# -*- coding:utf-8 -*-
from keras.preprocessing.image import ImageDataGenerator
from models.CnnModel import CnnModel

from models.keras_model import KerasClassifier
from utils import *

def lr_scheduler_sgd(epoch):
    new_lr = 0.1 * (0.1 ** (epoch // 50))
    print('new lr:%.2e' % new_lr)
    return new_lr


class CifarVGG(CnnModel):
    def __init__(self, param):
        super(CifarVGG, self).__init__(param)
        self.lr_scheduler_fun = lr_scheduler_sgd
        self.init_model()


    def init_model(self):
        K.set_learning_phase(1)
        model = Sequential()
        model.add(
            Conv2D(64, (3, 3), activation='relu', input_shape=self.input_shape,
                   name='block1_conv1', padding='same'))
        model.add(Conv2D(64, (3, 3), activation='relu', name='block1_conv2', padding='same'))
        model.add(MaxPooling2D(pool_size=(2, 2), name='block1_pool1'))
        model.add(Dropout(0.25, name='dropout_1'))
        model.add(Conv2D(128, (3, 3), activation='relu', name='block2_conv1', padding='same'))
        model.add(Conv2D(128, (3, 3), activation='relu', name='block2_conv2', padding='same'))
        model.add(MaxPooling2D(pool_size=(2, 2), name='block2_pool1'))
        model.add(Dropout(0.25, name='dropout_2'))
        model.add(Conv2D(128, (3, 3), activation='relu', name='block3_conv1', padding='same'))
        model.add(Conv2D(128, (3, 3), activation='relu', name='block3_conv2', padding='same'))
        model.add(Conv2D(128, (3, 3), activation='relu', name='block3_conv3', padding='same'))
        model.add(Conv2D(128, (3, 3), activation='relu', name='block3_conv4', padding='same'))
        model.add(MaxPooling2D(pool_size=(2, 2), name='block3_pool1'))
        model.add(Dropout(0.25, name='dropout_3'))
        model.add(Flatten(name='flatten1'))
        model.add(Dense(1024, activation='relu', name='dense_1'))
        model.add(Dropout(0.5, name='dropout_4'))
        model.add(Dense(1024, activation='relu', name='dense_2'))
        model.add(Dropout(0.5, name='dropout_5'))
        model.add(Dense(10, activation=None, name='predictions'))
        model.add(Activation('softmax', name='softmax'))

        model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])

        self.classifier = KerasClassifier(clip_values=(0, 255),preprocessing=preprocess_mnist, model=model, param=self.param)

    # def train(self, data):
    #     # default
    #     # nb_epochs=20
    #     # batch_size=128

    #     datagen = ImageDataGenerator(
    #         featurewise_center=False,  # set input mean to 0 over the dataset
    #         samplewise_center=False,  # set each sample mean to 0
    #         featurewise_std_normalization=False,  # divide inputs by std of the dataset
    #         samplewise_std_normalization=False,  # divide each input by its std
    #         zca_whitening=False,  # apply ZCA whitening
    #         zca_epsilon=1e-06,  # epsilon for ZCA whitening
    #         rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
    #         # randomly shift images horizontally (fraction of total width)
    #         width_shift_range=0.1,
    #         # randomly shift images vertically (fraction of total height)
    #         height_shift_range=0.1,
    #         shear_range=0.,  # set range for random shear
    #         zoom_range=0.,  # set range for random zoom
    #         channel_shift_range=0.,  # set range for random channel shifts
    #         # set mode for filling points outside the input boundaries
    #         fill_mode='nearest',
    #         cval=0.,  # value used for fill_mode = "constant"
    #         horizontal_flip=True,  # randomly flip images
    #         # validation_split=0.0
    #         preprocessing_function=preprocess_mnist
    #     )

    #     np_epochs = self.param.get_conf()['train_epoch']
    #     # Fit the model on the batches generated by datagen.flow().
    #     self.classifier.get_model().fit_generator(
    #         datagen.flow(data.x_train, to_categorical(data.y_train, 10), batch_size=self.batch_size),
    #         epochs=np_epochs,
    #         steps_per_epoch=data.x_train.shape[0] / self.batch_size,
    #         validation_data=(preprocess_mnist(data.x_test), to_categorical(data.y_test, 10)),
    #         validation_steps=data.x_train.shape[0] / self.batch_size,
    #         workers=4)

    